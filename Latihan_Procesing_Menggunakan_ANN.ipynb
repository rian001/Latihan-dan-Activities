{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Latihan Procesing Menggunakan ANN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqt_uijsgP1B"
      },
      "source": [
        "#Import library yang dibutuhkan\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "iMHhLE0agnqf",
        "outputId": "6b37d574-8922-4e48-bee1-b34a2336b591"
      },
      "source": [
        "# Load dataset\n",
        "kualitas = pd.read_csv('kualitas.csv')\n",
        "kualitas.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PH</th>\n",
              "      <th>cahaya</th>\n",
              "      <th>intensitas air</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>tinggi air</th>\n",
              "      <th>aksi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.5</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>622</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.7</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>26.9</td>\n",
              "      <td>79.0</td>\n",
              "      <td>557</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>491</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.5</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>345.0</td>\n",
              "      <td>12000</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>602.0</td>\n",
              "      <td>444</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    PH cahaya  ... tinggi air                                  aksi\n",
              "0  6.5    Ada  ...        622  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "1  5.7    Ada  ...        557  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "2  6.0    Ada  ...        491  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "3  6.5    Ada  ...      12000               Tidak melakukan apa-apa\n",
              "4  6.2    NaN  ...        444               Tidak melakukan apa-apa\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOWo3fKihBox",
        "outputId": "594862a9-e75c-40fc-eafc-9d02c4a49b72"
      },
      "source": [
        "# Menampilkan info\n",
        "kualitas.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 616 entries, 0 to 615\n",
            "Data columns (total 7 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   PH              600 non-null    float64\n",
            " 1   cahaya          590 non-null    object \n",
            " 2   intensitas air  616 non-null    object \n",
            " 3   suhu            589 non-null    float64\n",
            " 4   PPM             611 non-null    float64\n",
            " 5   tinggi air      616 non-null    int64  \n",
            " 6   aksi            616 non-null    object \n",
            "dtypes: float64(3), int64(1), object(3)\n",
            "memory usage: 33.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biQLxrKuhDhF",
        "outputId": "25b7a6c7-c603-460c-904a-7add0ec18b54"
      },
      "source": [
        "#Melihat pembagian data pada kolom label yaitu 'aksi'\n",
        "kualitas['aksi'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tidak melakukan apa-apa                 473\n",
              "Hidupkan Lampu                           92\n",
              "Hidupkan Lampu dan Pompa nutrisi TDS     39\n",
              "Hidupkan Pompa nutrisi TDS               12\n",
              "Name: aksi, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEVFVJZqhIvz",
        "outputId": "6a7485ed-d4d9-4d0e-b231-617f5cc86a98"
      },
      "source": [
        "kualitas['cahaya'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ada          302\n",
              "Tidak ada    288\n",
              "Name: cahaya, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLDlTgNOhQIS",
        "outputId": "46f4859d-3fb3-460e-a47c-243f5de40016"
      },
      "source": [
        "kualitas['intensitas air'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tinggi           154\n",
              "Rendah sekali    154\n",
              "Cukup            154\n",
              "Rendah           154\n",
              "Name: intensitas air, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBOpDwrUhSYk",
        "outputId": "632c52f2-5d3e-4a84-8911-85c98c82950f"
      },
      "source": [
        "kualitas.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 616 entries, 0 to 615\n",
            "Data columns (total 7 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   PH              600 non-null    float64\n",
            " 1   cahaya          590 non-null    object \n",
            " 2   intensitas air  616 non-null    object \n",
            " 3   suhu            589 non-null    float64\n",
            " 4   PPM             611 non-null    float64\n",
            " 5   tinggi air      616 non-null    int64  \n",
            " 6   aksi            616 non-null    object \n",
            "dtypes: float64(3), int64(1), object(3)\n",
            "memory usage: 33.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "RzQWnpwthV0Y",
        "outputId": "2f95273e-0a5b-402f-e69b-6ec3e83748e9"
      },
      "source": [
        "missing_data = pd.DataFrame({'total_missing': kualitas.isnull().sum(), 'perc_missing': (kualitas.isnull().sum()/616)*100})\n",
        "missing_data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_missing</th>\n",
              "      <th>perc_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PH</th>\n",
              "      <td>16</td>\n",
              "      <td>2.597403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cahaya</th>\n",
              "      <td>26</td>\n",
              "      <td>4.220779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intensitas air</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>suhu</th>\n",
              "      <td>27</td>\n",
              "      <td>4.383117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PPM</th>\n",
              "      <td>5</td>\n",
              "      <td>0.811688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tinggi air</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aksi</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                total_missing  perc_missing\n",
              "PH                         16      2.597403\n",
              "cahaya                     26      4.220779\n",
              "intensitas air              0      0.000000\n",
              "suhu                       27      4.383117\n",
              "PPM                         5      0.811688\n",
              "tinggi air                  0      0.000000\n",
              "aksi                        0      0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "af6H4BQWhaG2",
        "outputId": "47b2e5b3-32b0-459f-faae-800d1d5efe03"
      },
      "source": [
        "kualitas.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PH</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>tinggi air</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>600.000000</td>\n",
              "      <td>589.000000</td>\n",
              "      <td>611.000000</td>\n",
              "      <td>616.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.655167</td>\n",
              "      <td>29.364007</td>\n",
              "      <td>1032.836334</td>\n",
              "      <td>288.173701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.043234</td>\n",
              "      <td>14.937524</td>\n",
              "      <td>632.614766</td>\n",
              "      <td>622.457710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-300.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.500000</td>\n",
              "      <td>27.100000</td>\n",
              "      <td>487.500000</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.500000</td>\n",
              "      <td>29.900000</td>\n",
              "      <td>991.000000</td>\n",
              "      <td>230.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.700000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>1603.500000</td>\n",
              "      <td>429.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>40.600000</td>\n",
              "      <td>2149.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               PH        suhu          PPM    tinggi air\n",
              "count  600.000000  589.000000   611.000000    616.000000\n",
              "mean     6.655167   29.364007  1032.836334    288.173701\n",
              "std      3.043234   14.937524   632.614766    622.457710\n",
              "min      0.000000 -300.000000     1.000000      0.000000\n",
              "25%      5.500000   27.100000   487.500000     50.000000\n",
              "50%      6.500000   29.900000   991.000000    230.000000\n",
              "75%      7.700000   33.000000  1603.500000    429.500000\n",
              "max     14.000000   40.600000  2149.000000  12000.000000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "t_mEKCwXhe7M",
        "outputId": "5971dd71-ddb8-43be-9f36-bfc8442399a2"
      },
      "source": [
        "# Menetukan Aksi\n",
        "# Hapus pH karena tidak berpengaruh pada aksi\n",
        "del kualitas[\"PH\"]\n",
        "kualitas.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cahaya</th>\n",
              "      <th>intensitas air</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>tinggi air</th>\n",
              "      <th>aksi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>622</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>26.9</td>\n",
              "      <td>79.0</td>\n",
              "      <td>557</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>491</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>345.0</td>\n",
              "      <td>12000</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>602.0</td>\n",
              "      <td>444</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  cahaya intensitas air  ...  tinggi air                                  aksi\n",
              "0    Ada         Tinggi  ...         622  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "1    Ada         Tinggi  ...         557  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "2    Ada         Tinggi  ...         491  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "3    Ada         Tinggi  ...       12000               Tidak melakukan apa-apa\n",
              "4    NaN         Tinggi  ...         444               Tidak melakukan apa-apa\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "-xOp-iaFhiwM",
        "outputId": "f9dab1be-1f75-448a-9e08-513957101843"
      },
      "source": [
        "# Hapus tinggi air karena tidak berpengaruh pada aksi\n",
        "del kualitas[\"tinggi air\"]\n",
        "kualitas.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cahaya</th>\n",
              "      <th>intensitas air</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>aksi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>26.9</td>\n",
              "      <td>79.0</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ada</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>345.0</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Tinggi</td>\n",
              "      <td>27.1</td>\n",
              "      <td>602.0</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  cahaya intensitas air  suhu    PPM                                  aksi\n",
              "0    Ada         Tinggi  27.0  188.0  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "1    Ada         Tinggi  26.9   79.0  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "2    Ada         Tinggi  27.0   11.0  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "3    Ada         Tinggi  27.1  345.0               Tidak melakukan apa-apa\n",
              "4    NaN         Tinggi  27.1  602.0               Tidak melakukan apa-apa"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBkq4P_Ghmem",
        "outputId": "98a2b543-adce-43c9-9f45-3a2c891016ff"
      },
      "source": [
        "kualitas.columns"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cahaya', 'intensitas air', 'suhu', 'PPM', 'aksi'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpodqvcHhyLI"
      },
      "source": [
        "column = ['cahaya', 'intensitas_air', 'suhu', 'PPM', 'aksi']\n",
        "kualitas.columns = column"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJWpwnd-hqki",
        "outputId": "91caa8d1-f893-4bd5-9f56-2b6de5684fd6"
      },
      "source": [
        "kualitas.columns"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cahaya', 'intensitas_air', 'suhu', 'PPM', 'aksi'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "j_DK7NwXh5ue",
        "outputId": "ae623dbb-51ca-40b8-b0d8-da902325f816"
      },
      "source": [
        "missing_data = pd.DataFrame({'total_missing': kualitas.isnull().sum(), 'perc_missing': (kualitas.isnull().sum()/616)*100})\n",
        "missing_data"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_missing</th>\n",
              "      <th>perc_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cahaya</th>\n",
              "      <td>26</td>\n",
              "      <td>4.220779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intensitas_air</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>suhu</th>\n",
              "      <td>27</td>\n",
              "      <td>4.383117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PPM</th>\n",
              "      <td>5</td>\n",
              "      <td>0.811688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aksi</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                total_missing  perc_missing\n",
              "cahaya                     26      4.220779\n",
              "intensitas_air              0      0.000000\n",
              "suhu                       27      4.383117\n",
              "PPM                         5      0.811688\n",
              "aksi                        0      0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "KyGM7D1dh7we",
        "outputId": "f6272b88-34b9-450b-8d74-65efbe634ca3"
      },
      "source": [
        "# Mengubah data ke numerical\n",
        "def getNumber(str):\n",
        "    if str==\"Rendah sekali\":\n",
        "        return 1.0\n",
        "    elif str==\"Rendah\":\n",
        "        return 2.0\n",
        "    elif str==\"Cukup\":\n",
        "        return 3.0\n",
        "    elif str==\"Tinggi\":\n",
        "        return 4.0\n",
        "    else:\n",
        "        return str\n",
        "kualitas[\"intensitas_air\"]=kualitas[\"intensitas_air\"].apply(getNumber)\n",
        "\n",
        "kualitas.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cahaya</th>\n",
              "      <th>intensitas_air</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>aksi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ada</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ada</td>\n",
              "      <td>4.0</td>\n",
              "      <td>26.9</td>\n",
              "      <td>79.0</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ada</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Hidupkan Lampu dan Pompa nutrisi TDS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ada</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.1</td>\n",
              "      <td>345.0</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.1</td>\n",
              "      <td>602.0</td>\n",
              "      <td>Tidak melakukan apa-apa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  cahaya  intensitas_air  suhu    PPM                                  aksi\n",
              "0    Ada             4.0  27.0  188.0  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "1    Ada             4.0  26.9   79.0  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "2    Ada             4.0  27.0   11.0  Hidupkan Lampu dan Pompa nutrisi TDS\n",
              "3    Ada             4.0  27.1  345.0               Tidak melakukan apa-apa\n",
              "4    NaN             4.0  27.1  602.0               Tidak melakukan apa-apa"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "DdbUK6iPiAHx",
        "outputId": "d25e9cc6-d589-456c-d838-a075f7aef3cc"
      },
      "source": [
        "def getNumber(str):\n",
        "    if str==\"Tidak melakukan apa-apa\":\n",
        "        return 1.0\n",
        "    elif str==\"Hidupkan Lampu\":\n",
        "        return 2.0\n",
        "    elif str==\"Hidupkan Pompa nutrisi TDS\":\n",
        "        return 3.0\n",
        "    elif str==\"Hidupkan Lampu dan Pompa nutrisi TDS\":\n",
        "        return 4.0\n",
        "    else:\n",
        "        return str\n",
        "kualitas[\"aksi\"]=kualitas[\"aksi\"].apply(getNumber)\n",
        "\n",
        "kualitas.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cahaya</th>\n",
              "      <th>intensitas_air</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>aksi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ada</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ada</td>\n",
              "      <td>4.0</td>\n",
              "      <td>26.9</td>\n",
              "      <td>79.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ada</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ada</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.1</td>\n",
              "      <td>345.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.1</td>\n",
              "      <td>602.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  cahaya  intensitas_air  suhu    PPM  aksi\n",
              "0    Ada             4.0  27.0  188.0   4.0\n",
              "1    Ada             4.0  26.9   79.0   4.0\n",
              "2    Ada             4.0  27.0   11.0   4.0\n",
              "3    Ada             4.0  27.1  345.0   1.0\n",
              "4    NaN             4.0  27.1  602.0   1.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "4cxJhzH6iD3G",
        "outputId": "bcba60b9-682a-41b3-e514-d186adbe9af2"
      },
      "source": [
        "def getNumber(str):\n",
        "    if str==\"Ada\":\n",
        "        return 0.0\n",
        "    elif str==\"Tidak ada\":\n",
        "        return 1.0\n",
        "    else:\n",
        "        return str\n",
        "kualitas[\"cahaya\"]=kualitas[\"cahaya\"].apply(getNumber)\n",
        "\n",
        "kualitas.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cahaya</th>\n",
              "      <th>intensitas_air</th>\n",
              "      <th>suhu</th>\n",
              "      <th>PPM</th>\n",
              "      <th>aksi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>26.9</td>\n",
              "      <td>79.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.1</td>\n",
              "      <td>345.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.1</td>\n",
              "      <td>602.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cahaya  intensitas_air  suhu    PPM  aksi\n",
              "0     0.0             4.0  27.0  188.0   4.0\n",
              "1     0.0             4.0  26.9   79.0   4.0\n",
              "2     0.0             4.0  27.0   11.0   4.0\n",
              "3     0.0             4.0  27.1  345.0   1.0\n",
              "4     NaN             4.0  27.1  602.0   1.0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "rBc2fXi2iHvM",
        "outputId": "0566d93e-2cb7-48b5-8684-4d10205eb6fa"
      },
      "source": [
        "missing_data = pd.DataFrame({'total_missing': kualitas.isnull().sum(), 'perc_missing': (kualitas.isnull().sum()/616)*100})\n",
        "missing_data"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_missing</th>\n",
              "      <th>perc_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cahaya</th>\n",
              "      <td>26</td>\n",
              "      <td>4.220779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intensitas_air</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>suhu</th>\n",
              "      <td>27</td>\n",
              "      <td>4.383117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PPM</th>\n",
              "      <td>5</td>\n",
              "      <td>0.811688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aksi</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                total_missing  perc_missing\n",
              "cahaya                     26      4.220779\n",
              "intensitas_air              0      0.000000\n",
              "suhu                       27      4.383117\n",
              "PPM                         5      0.811688\n",
              "aksi                        0      0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lso2O01-iNJk",
        "outputId": "8188633a-f055-45ca-e378-f49af11e7c84"
      },
      "source": [
        "# Mengelompokkan missing value\n",
        "column_missing = ['cahaya', 'intensitas_air', 'suhu', 'PPM']\n",
        "column_missing"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cahaya', 'intensitas_air', 'suhu', 'PPM']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty4SLRcYiSTi",
        "outputId": "7f11f82f-9df5-405c-dc43-a72199ec5892"
      },
      "source": [
        "# Menyelesaikan missing value\n",
        "for col in column_missing:\n",
        "  kualitas[col].replace(np.nan, kualitas[col].mean(), inplace=True)\n",
        "\n",
        "kualitas.isnull().sum()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cahaya            0\n",
              "intensitas_air    0\n",
              "suhu              0\n",
              "PPM               0\n",
              "aksi              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba5ikKrmiUGa",
        "outputId": "d9f57a09-9c4b-4396-8f58-7a8afc9c0a15"
      },
      "source": [
        "kualitas.columns"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cahaya', 'intensitas_air', 'suhu', 'PPM', 'aksi'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "wBwjW9KuiZYo",
        "outputId": "abc4fcbf-3c61-4ce0-86e3-a1ba2bc0b252"
      },
      "source": [
        "num_cols = ['cahaya', 'intensitas_air', 'suhu', 'PPM']\n",
        "plt.figure(figsize = (19, 9))\n",
        "kualitas[num_cols].boxplot()\n",
        "plt.title(\"Variabel Numerik pada Dataset Kualitas Air\", fontsize = 20)\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1368x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hUr7g2JidJz",
        "outputId": "a3c8e259-1c42-4962-f8ca-4f291ca800cd"
      },
      "source": [
        "# Didefinisikan menjadi X\n",
        "X = kualitas.iloc[:, :4].values\n",
        "X"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.000e+00, 4.000e+00, 2.700e+01, 1.880e+02],\n",
              "       [0.000e+00, 4.000e+00, 2.690e+01, 7.900e+01],\n",
              "       [0.000e+00, 4.000e+00, 2.700e+01, 1.100e+01],\n",
              "       ...,\n",
              "       [0.000e+00, 1.000e+00, 2.530e+01, 7.930e+02],\n",
              "       [0.000e+00, 1.000e+00, 2.540e+01, 1.052e+03],\n",
              "       [0.000e+00, 1.000e+00, 2.530e+01, 9.770e+02]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIFklG4xigkQ",
        "outputId": "84e61bd9-9543-46f8-eecb-68cd8ca9c8e0"
      },
      "source": [
        "# Didefinisikan Menjadi Y\n",
        "Y = kualitas.iloc[:, 4].values\n",
        "Y"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4., 4., 4., 1., 1., 2., 2., 2., 1., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "       4., 4., 4., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 1.,\n",
              "       4., 4., 4., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 4., 4., 4., 4., 4., 4., 4., 4., 4., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 1., 2., 2., 2., 2., 2., 1.,\n",
              "       1., 2., 2., 1., 1., 2., 2., 4., 1., 4., 4., 4., 1., 4., 1., 1., 1.,\n",
              "       2., 2., 1., 1., 1., 1., 2., 2., 1., 1., 2., 1., 2., 1., 1., 1., 1.,\n",
              "       1., 2., 2., 2., 1., 1., 1., 1., 4., 1., 4., 1., 4., 4., 1., 1., 2.,\n",
              "       1., 2., 2., 1., 1., 2., 1., 2., 1., 1., 2., 1., 1., 1., 2., 1., 1.,\n",
              "       1., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 1., 1., 2., 4.,\n",
              "       2., 1., 2., 2., 2., 4., 2., 2., 4., 2., 2., 2., 4., 2., 2., 4., 2.,\n",
              "       4., 2., 2., 2., 2., 4., 2., 2., 4., 2., 4., 2., 2., 2., 4., 2., 2.,\n",
              "       4., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3cRB9Zlin0r",
        "outputId": "057bcb40-3a31-4229-92c9-511e8110a2f2"
      },
      "source": [
        "# Fungsi SMOTE ke dataset\n",
        "# Menghitung data pada Y\n",
        "counter = Counter(Y)\n",
        "print(counter)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1.0: 473, 2.0: 92, 4.0: 39, 3.0: 12})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1tLnqpiirg_"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE(k_neighbors = 5)\n",
        "X_smote, Y_smote = oversample.fit_resample(X, Y)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq3OJNzyiwYc",
        "outputId": "0acc8fc9-9324-4725-c9a8-5c972fe90b82"
      },
      "source": [
        "# Menghitung data pada Y\n",
        "counter = Counter(Y)\n",
        "print(counter)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1.0: 473, 2.0: 92, 4.0: 39, 3.0: 12})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2-yBJkWjDW0",
        "outputId": "c3234e1e-1b2b-4753-9778-d32087609f48"
      },
      "source": [
        "# Melakukan trasformasi mengunakan MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler =  MinMaxScaler()\n",
        "\n",
        "# Trasform data\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(X_scaled)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         1.         0.96007046 0.08705773]\n",
            " [0.         1.         0.95977686 0.03631285]\n",
            " [0.         1.         0.96007046 0.00465549]\n",
            " ...\n",
            " [0.         0.         0.95507927 0.36871508]\n",
            " [0.         0.         0.95537287 0.48929236]\n",
            " [0.         0.         0.95507927 0.45437616]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt2PgL9-jSRd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "#membagi data test dan validation\n",
        "(X_train, X_valid) = X_train[148:], X_train[:148]\n",
        "(Y_train, Y_valid) = Y_train[148:], Y_train[:148]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn3iihTokNXQ",
        "outputId": "93a9aa7e-9f69-49c9-e6ef-80dd67166c9b"
      },
      "source": [
        "import tensorflow as tf # Backpropagation\n",
        "\n",
        "model = tf.keras.models.Sequential() # Membuat model arsitektur\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units = 3, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dense(units = 9, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dense(units = 3))\n",
        "model.compile(loss = 'mean_absolute_error', optimizer = tf.keras.optimizers.Adam(0.001))\n",
        "\n",
        "tes_ngasal = model.fit(X_train, Y_train, epochs = 500, batch_size = 16, validation_data = (X_valid, Y_valid))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "22/22 [==============================] - 1s 8ms/step - loss: 1.1400 - val_loss: 1.2169\n",
            "Epoch 2/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.9902 - val_loss: 1.0533\n",
            "Epoch 3/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.8262 - val_loss: 0.8963\n",
            "Epoch 4/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6989 - val_loss: 0.8085\n",
            "Epoch 5/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6257 - val_loss: 0.7438\n",
            "Epoch 6/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5606 - val_loss: 0.6777\n",
            "Epoch 7/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4955 - val_loss: 0.6115\n",
            "Epoch 8/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4319 - val_loss: 0.5550\n",
            "Epoch 9/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3893 - val_loss: 0.5287\n",
            "Epoch 10/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3699 - val_loss: 0.5167\n",
            "Epoch 11/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3632 - val_loss: 0.5106\n",
            "Epoch 12/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3578 - val_loss: 0.5066\n",
            "Epoch 13/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3532 - val_loss: 0.5022\n",
            "Epoch 14/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3501 - val_loss: 0.4994\n",
            "Epoch 15/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3477 - val_loss: 0.4969\n",
            "Epoch 16/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3451 - val_loss: 0.4956\n",
            "Epoch 17/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3433 - val_loss: 0.4944\n",
            "Epoch 18/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3422 - val_loss: 0.4930\n",
            "Epoch 19/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3412 - val_loss: 0.4918\n",
            "Epoch 20/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3404 - val_loss: 0.4913\n",
            "Epoch 21/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3399 - val_loss: 0.4920\n",
            "Epoch 22/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3397 - val_loss: 0.4902\n",
            "Epoch 23/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3392 - val_loss: 0.4893\n",
            "Epoch 24/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3383 - val_loss: 0.4893\n",
            "Epoch 25/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3376 - val_loss: 0.4889\n",
            "Epoch 26/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3370 - val_loss: 0.4880\n",
            "Epoch 27/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3371 - val_loss: 0.4876\n",
            "Epoch 28/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3364 - val_loss: 0.4865\n",
            "Epoch 29/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3357 - val_loss: 0.4860\n",
            "Epoch 30/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3354 - val_loss: 0.4863\n",
            "Epoch 31/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3350 - val_loss: 0.4853\n",
            "Epoch 32/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3344 - val_loss: 0.4849\n",
            "Epoch 33/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3340 - val_loss: 0.4854\n",
            "Epoch 34/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3337 - val_loss: 0.4842\n",
            "Epoch 35/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3337 - val_loss: 0.4847\n",
            "Epoch 36/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3331 - val_loss: 0.4838\n",
            "Epoch 37/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3328 - val_loss: 0.4832\n",
            "Epoch 38/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3330 - val_loss: 0.4839\n",
            "Epoch 39/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3330 - val_loss: 0.4868\n",
            "Epoch 40/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3328 - val_loss: 0.4829\n",
            "Epoch 41/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3317 - val_loss: 0.4827\n",
            "Epoch 42/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3322 - val_loss: 0.4828\n",
            "Epoch 43/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3315 - val_loss: 0.4824\n",
            "Epoch 44/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3314 - val_loss: 0.4825\n",
            "Epoch 45/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3323 - val_loss: 0.4835\n",
            "Epoch 46/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3315 - val_loss: 0.4827\n",
            "Epoch 47/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3311 - val_loss: 0.4822\n",
            "Epoch 48/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3306 - val_loss: 0.4819\n",
            "Epoch 49/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3310 - val_loss: 0.4823\n",
            "Epoch 50/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3308 - val_loss: 0.4826\n",
            "Epoch 51/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3309 - val_loss: 0.4819\n",
            "Epoch 52/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3303 - val_loss: 0.4821\n",
            "Epoch 53/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3301 - val_loss: 0.4821\n",
            "Epoch 54/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3306 - val_loss: 0.4819\n",
            "Epoch 55/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3303 - val_loss: 0.4824\n",
            "Epoch 56/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3308 - val_loss: 0.4816\n",
            "Epoch 57/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3302 - val_loss: 0.4814\n",
            "Epoch 58/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3300 - val_loss: 0.4815\n",
            "Epoch 59/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3303 - val_loss: 0.4831\n",
            "Epoch 60/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3305 - val_loss: 0.4819\n",
            "Epoch 61/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3300 - val_loss: 0.4818\n",
            "Epoch 62/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3300 - val_loss: 0.4820\n",
            "Epoch 63/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3300 - val_loss: 0.4825\n",
            "Epoch 64/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3301 - val_loss: 0.4821\n",
            "Epoch 65/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3299 - val_loss: 0.4817\n",
            "Epoch 66/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3300 - val_loss: 0.4817\n",
            "Epoch 67/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3297 - val_loss: 0.4819\n",
            "Epoch 68/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3296 - val_loss: 0.4817\n",
            "Epoch 69/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3297 - val_loss: 0.4821\n",
            "Epoch 70/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3297 - val_loss: 0.4827\n",
            "Epoch 71/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3304 - val_loss: 0.4819\n",
            "Epoch 72/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3296 - val_loss: 0.4826\n",
            "Epoch 73/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3297 - val_loss: 0.4818\n",
            "Epoch 74/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3301 - val_loss: 0.4820\n",
            "Epoch 75/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3296 - val_loss: 0.4830\n",
            "Epoch 76/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3303 - val_loss: 0.4841\n",
            "Epoch 77/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3298 - val_loss: 0.4826\n",
            "Epoch 78/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3296 - val_loss: 0.4824\n",
            "Epoch 79/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3295 - val_loss: 0.4825\n",
            "Epoch 80/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3299 - val_loss: 0.4833\n",
            "Epoch 81/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3299 - val_loss: 0.4826\n",
            "Epoch 82/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3293 - val_loss: 0.4819\n",
            "Epoch 83/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3295 - val_loss: 0.4829\n",
            "Epoch 84/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3294 - val_loss: 0.4829\n",
            "Epoch 85/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3294 - val_loss: 0.4826\n",
            "Epoch 86/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3293 - val_loss: 0.4825\n",
            "Epoch 87/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3291 - val_loss: 0.4822\n",
            "Epoch 88/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3291 - val_loss: 0.4826\n",
            "Epoch 89/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3294 - val_loss: 0.4823\n",
            "Epoch 90/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3295 - val_loss: 0.4824\n",
            "Epoch 91/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3300 - val_loss: 0.4837\n",
            "Epoch 92/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3292 - val_loss: 0.4819\n",
            "Epoch 93/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3293 - val_loss: 0.4825\n",
            "Epoch 94/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3295 - val_loss: 0.4820\n",
            "Epoch 95/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3292 - val_loss: 0.4826\n",
            "Epoch 96/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3296 - val_loss: 0.4841\n",
            "Epoch 97/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3298 - val_loss: 0.4825\n",
            "Epoch 98/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3290 - val_loss: 0.4830\n",
            "Epoch 99/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3295 - val_loss: 0.4821\n",
            "Epoch 100/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.4824\n",
            "Epoch 101/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3291 - val_loss: 0.4821\n",
            "Epoch 102/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3290 - val_loss: 0.4823\n",
            "Epoch 103/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3295 - val_loss: 0.4822\n",
            "Epoch 104/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3291 - val_loss: 0.4822\n",
            "Epoch 105/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4823\n",
            "Epoch 106/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.4827\n",
            "Epoch 107/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3294 - val_loss: 0.4823\n",
            "Epoch 108/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3294 - val_loss: 0.4819\n",
            "Epoch 109/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3288 - val_loss: 0.4822\n",
            "Epoch 110/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3288 - val_loss: 0.4827\n",
            "Epoch 111/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.4831\n",
            "Epoch 112/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3293 - val_loss: 0.4823\n",
            "Epoch 113/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3290 - val_loss: 0.4825\n",
            "Epoch 114/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3290 - val_loss: 0.4826\n",
            "Epoch 115/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3286 - val_loss: 0.4821\n",
            "Epoch 116/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4822\n",
            "Epoch 117/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4821\n",
            "Epoch 118/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3294 - val_loss: 0.4833\n",
            "Epoch 119/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3293 - val_loss: 0.4830\n",
            "Epoch 120/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3292 - val_loss: 0.4829\n",
            "Epoch 121/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3292 - val_loss: 0.4824\n",
            "Epoch 122/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.4828\n",
            "Epoch 123/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4828\n",
            "Epoch 124/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4821\n",
            "Epoch 125/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4820\n",
            "Epoch 126/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4824\n",
            "Epoch 127/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.4822\n",
            "Epoch 128/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3290 - val_loss: 0.4823\n",
            "Epoch 129/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4823\n",
            "Epoch 130/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.4823\n",
            "Epoch 131/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4827\n",
            "Epoch 132/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3288 - val_loss: 0.4824\n",
            "Epoch 133/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4824\n",
            "Epoch 134/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4825\n",
            "Epoch 135/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4823\n",
            "Epoch 136/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.4823\n",
            "Epoch 137/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4823\n",
            "Epoch 138/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4823\n",
            "Epoch 139/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4832\n",
            "Epoch 140/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4826\n",
            "Epoch 141/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3294 - val_loss: 0.4858\n",
            "Epoch 142/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3303 - val_loss: 0.4838\n",
            "Epoch 143/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3291 - val_loss: 0.4824\n",
            "Epoch 144/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.4827\n",
            "Epoch 145/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4823\n",
            "Epoch 146/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4831\n",
            "Epoch 147/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.4833\n",
            "Epoch 148/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3290 - val_loss: 0.4828\n",
            "Epoch 149/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.4827\n",
            "Epoch 150/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4825\n",
            "Epoch 151/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4822\n",
            "Epoch 152/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.4826\n",
            "Epoch 153/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.4825\n",
            "Epoch 154/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3285 - val_loss: 0.4823\n",
            "Epoch 155/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4825\n",
            "Epoch 156/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3291 - val_loss: 0.4834\n",
            "Epoch 157/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.4825\n",
            "Epoch 158/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.4821\n",
            "Epoch 159/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4823\n",
            "Epoch 160/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4822\n",
            "Epoch 161/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4828\n",
            "Epoch 162/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4823\n",
            "Epoch 163/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4824\n",
            "Epoch 164/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4829\n",
            "Epoch 165/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4823\n",
            "Epoch 166/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4823\n",
            "Epoch 167/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4823\n",
            "Epoch 168/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4827\n",
            "Epoch 169/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4823\n",
            "Epoch 170/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4831\n",
            "Epoch 171/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4826\n",
            "Epoch 172/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.4834\n",
            "Epoch 173/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3294 - val_loss: 0.4821\n",
            "Epoch 174/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4830\n",
            "Epoch 175/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.4830\n",
            "Epoch 176/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4825\n",
            "Epoch 177/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4822\n",
            "Epoch 178/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4822\n",
            "Epoch 179/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3281 - val_loss: 0.4824\n",
            "Epoch 180/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3286 - val_loss: 0.4825\n",
            "Epoch 181/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4822\n",
            "Epoch 182/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4824\n",
            "Epoch 183/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4840\n",
            "Epoch 184/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4826\n",
            "Epoch 185/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.4826\n",
            "Epoch 186/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3288 - val_loss: 0.4822\n",
            "Epoch 187/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.4823\n",
            "Epoch 188/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4834\n",
            "Epoch 189/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4829\n",
            "Epoch 190/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.4822\n",
            "Epoch 191/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4823\n",
            "Epoch 192/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4831\n",
            "Epoch 193/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4825\n",
            "Epoch 194/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.4822\n",
            "Epoch 195/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4837\n",
            "Epoch 196/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.4845\n",
            "Epoch 197/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3292 - val_loss: 0.4825\n",
            "Epoch 198/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4826\n",
            "Epoch 199/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4827\n",
            "Epoch 200/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.4822\n",
            "Epoch 201/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4822\n",
            "Epoch 202/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.4824\n",
            "Epoch 203/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4831\n",
            "Epoch 204/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4822\n",
            "Epoch 205/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4828\n",
            "Epoch 206/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3291 - val_loss: 0.4822\n",
            "Epoch 207/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3288 - val_loss: 0.4823\n",
            "Epoch 208/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4823\n",
            "Epoch 209/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4821\n",
            "Epoch 210/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4830\n",
            "Epoch 211/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3286 - val_loss: 0.4822\n",
            "Epoch 212/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4823\n",
            "Epoch 213/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4825\n",
            "Epoch 214/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4824\n",
            "Epoch 215/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4822\n",
            "Epoch 216/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4827\n",
            "Epoch 217/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3280 - val_loss: 0.4822\n",
            "Epoch 218/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4825\n",
            "Epoch 219/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3281 - val_loss: 0.4824\n",
            "Epoch 220/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4823\n",
            "Epoch 221/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4822\n",
            "Epoch 222/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4824\n",
            "Epoch 223/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.4822\n",
            "Epoch 224/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3283 - val_loss: 0.4822\n",
            "Epoch 225/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.4822\n",
            "Epoch 226/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4842\n",
            "Epoch 227/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4824\n",
            "Epoch 228/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4827\n",
            "Epoch 229/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3283 - val_loss: 0.4836\n",
            "Epoch 230/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4828\n",
            "Epoch 231/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4826\n",
            "Epoch 232/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4824\n",
            "Epoch 233/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4829\n",
            "Epoch 234/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4828\n",
            "Epoch 235/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4823\n",
            "Epoch 236/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.4831\n",
            "Epoch 237/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3283 - val_loss: 0.4826\n",
            "Epoch 238/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4822\n",
            "Epoch 239/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4822\n",
            "Epoch 240/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4821\n",
            "Epoch 241/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4821\n",
            "Epoch 242/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4822\n",
            "Epoch 243/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3282 - val_loss: 0.4822\n",
            "Epoch 244/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4823\n",
            "Epoch 245/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4823\n",
            "Epoch 246/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3288 - val_loss: 0.4824\n",
            "Epoch 247/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3282 - val_loss: 0.4824\n",
            "Epoch 248/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3282 - val_loss: 0.4825\n",
            "Epoch 249/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4822\n",
            "Epoch 250/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3291 - val_loss: 0.4825\n",
            "Epoch 251/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4844\n",
            "Epoch 252/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3298 - val_loss: 0.4828\n",
            "Epoch 253/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3292 - val_loss: 0.4821\n",
            "Epoch 254/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4824\n",
            "Epoch 255/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4829\n",
            "Epoch 256/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.4825\n",
            "Epoch 257/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4823\n",
            "Epoch 258/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4825\n",
            "Epoch 259/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4824\n",
            "Epoch 260/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3280 - val_loss: 0.4824\n",
            "Epoch 261/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4824\n",
            "Epoch 262/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4826\n",
            "Epoch 263/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3281 - val_loss: 0.4825\n",
            "Epoch 264/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4821\n",
            "Epoch 265/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4823\n",
            "Epoch 266/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4829\n",
            "Epoch 267/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4823\n",
            "Epoch 268/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3280 - val_loss: 0.4827\n",
            "Epoch 269/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4824\n",
            "Epoch 270/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4822\n",
            "Epoch 271/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4831\n",
            "Epoch 272/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4825\n",
            "Epoch 273/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4826\n",
            "Epoch 274/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4832\n",
            "Epoch 275/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3290 - val_loss: 0.4823\n",
            "Epoch 276/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4822\n",
            "Epoch 277/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4826\n",
            "Epoch 278/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4829\n",
            "Epoch 279/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4824\n",
            "Epoch 280/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4831\n",
            "Epoch 281/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3288 - val_loss: 0.4829\n",
            "Epoch 282/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4821\n",
            "Epoch 283/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4826\n",
            "Epoch 284/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4825\n",
            "Epoch 285/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3282 - val_loss: 0.4822\n",
            "Epoch 286/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4824\n",
            "Epoch 287/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4832\n",
            "Epoch 288/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4820\n",
            "Epoch 289/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4824\n",
            "Epoch 290/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.4824\n",
            "Epoch 291/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3294 - val_loss: 0.4825\n",
            "Epoch 292/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4822\n",
            "Epoch 293/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3288 - val_loss: 0.4823\n",
            "Epoch 294/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4823\n",
            "Epoch 295/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4823\n",
            "Epoch 296/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4823\n",
            "Epoch 297/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3280 - val_loss: 0.4821\n",
            "Epoch 298/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3286 - val_loss: 0.4824\n",
            "Epoch 299/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4828\n",
            "Epoch 300/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4823\n",
            "Epoch 301/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4823\n",
            "Epoch 302/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4831\n",
            "Epoch 303/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.4825\n",
            "Epoch 304/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4828\n",
            "Epoch 305/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4834\n",
            "Epoch 306/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.4832\n",
            "Epoch 307/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4826\n",
            "Epoch 308/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4821\n",
            "Epoch 309/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4836\n",
            "Epoch 310/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4825\n",
            "Epoch 311/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3283 - val_loss: 0.4821\n",
            "Epoch 312/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.4822\n",
            "Epoch 313/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4822\n",
            "Epoch 314/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4827\n",
            "Epoch 315/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4823\n",
            "Epoch 316/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4820\n",
            "Epoch 317/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4821\n",
            "Epoch 318/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4827\n",
            "Epoch 319/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4822\n",
            "Epoch 320/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3280 - val_loss: 0.4823\n",
            "Epoch 321/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4822\n",
            "Epoch 322/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4823\n",
            "Epoch 323/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4821\n",
            "Epoch 324/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4822\n",
            "Epoch 325/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4825\n",
            "Epoch 326/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.4824\n",
            "Epoch 327/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4821\n",
            "Epoch 328/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4821\n",
            "Epoch 329/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4831\n",
            "Epoch 330/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4823\n",
            "Epoch 331/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4822\n",
            "Epoch 332/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4827\n",
            "Epoch 333/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4824\n",
            "Epoch 334/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.4822\n",
            "Epoch 335/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4821\n",
            "Epoch 336/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4822\n",
            "Epoch 337/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3295 - val_loss: 0.4827\n",
            "Epoch 338/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4826\n",
            "Epoch 339/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.4821\n",
            "Epoch 340/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.4825\n",
            "Epoch 341/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4821\n",
            "Epoch 342/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4823\n",
            "Epoch 343/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4827\n",
            "Epoch 344/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4822\n",
            "Epoch 345/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4823\n",
            "Epoch 346/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4829\n",
            "Epoch 347/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4820\n",
            "Epoch 348/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4826\n",
            "Epoch 349/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4826\n",
            "Epoch 350/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4830\n",
            "Epoch 351/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4827\n",
            "Epoch 352/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3288 - val_loss: 0.4820\n",
            "Epoch 353/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3286 - val_loss: 0.4847\n",
            "Epoch 354/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.4824\n",
            "Epoch 355/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3282 - val_loss: 0.4820\n",
            "Epoch 356/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3291 - val_loss: 0.4827\n",
            "Epoch 357/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4821\n",
            "Epoch 358/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4820\n",
            "Epoch 359/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3282 - val_loss: 0.4823\n",
            "Epoch 360/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4820\n",
            "Epoch 361/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.4826\n",
            "Epoch 362/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4820\n",
            "Epoch 363/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4832\n",
            "Epoch 364/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4828\n",
            "Epoch 365/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4821\n",
            "Epoch 366/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.4835\n",
            "Epoch 367/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4819\n",
            "Epoch 368/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4822\n",
            "Epoch 369/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.4822\n",
            "Epoch 370/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3286 - val_loss: 0.4831\n",
            "Epoch 371/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4835\n",
            "Epoch 372/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4825\n",
            "Epoch 373/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4821\n",
            "Epoch 374/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4822\n",
            "Epoch 375/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4821\n",
            "Epoch 376/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4838\n",
            "Epoch 377/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4824\n",
            "Epoch 378/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4827\n",
            "Epoch 379/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4827\n",
            "Epoch 380/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4822\n",
            "Epoch 381/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4820\n",
            "Epoch 382/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4821\n",
            "Epoch 383/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4825\n",
            "Epoch 384/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4827\n",
            "Epoch 385/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4822\n",
            "Epoch 386/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4823\n",
            "Epoch 387/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3280 - val_loss: 0.4821\n",
            "Epoch 388/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3278 - val_loss: 0.4825\n",
            "Epoch 389/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4821\n",
            "Epoch 390/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4822\n",
            "Epoch 391/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4825\n",
            "Epoch 392/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3285 - val_loss: 0.4825\n",
            "Epoch 393/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4820\n",
            "Epoch 394/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4820\n",
            "Epoch 395/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4821\n",
            "Epoch 396/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4819\n",
            "Epoch 397/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4823\n",
            "Epoch 398/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4820\n",
            "Epoch 399/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3281 - val_loss: 0.4820\n",
            "Epoch 400/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4823\n",
            "Epoch 401/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.4823\n",
            "Epoch 402/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4824\n",
            "Epoch 403/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4821\n",
            "Epoch 404/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.4823\n",
            "Epoch 405/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4828\n",
            "Epoch 406/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.4844\n",
            "Epoch 407/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3292 - val_loss: 0.4821\n",
            "Epoch 408/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4825\n",
            "Epoch 409/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4821\n",
            "Epoch 410/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4820\n",
            "Epoch 411/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3280 - val_loss: 0.4825\n",
            "Epoch 412/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4823\n",
            "Epoch 413/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4822\n",
            "Epoch 414/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4820\n",
            "Epoch 415/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3278 - val_loss: 0.4820\n",
            "Epoch 416/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4819\n",
            "Epoch 417/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4819\n",
            "Epoch 418/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3278 - val_loss: 0.4833\n",
            "Epoch 419/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4819\n",
            "Epoch 420/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4821\n",
            "Epoch 421/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4829\n",
            "Epoch 422/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3279 - val_loss: 0.4824\n",
            "Epoch 423/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4836\n",
            "Epoch 424/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4823\n",
            "Epoch 425/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3278 - val_loss: 0.4821\n",
            "Epoch 426/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4820\n",
            "Epoch 427/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4820\n",
            "Epoch 428/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3292 - val_loss: 0.4854\n",
            "Epoch 429/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3304 - val_loss: 0.4823\n",
            "Epoch 430/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3288 - val_loss: 0.4832\n",
            "Epoch 431/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4820\n",
            "Epoch 432/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4821\n",
            "Epoch 433/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3281 - val_loss: 0.4821\n",
            "Epoch 434/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4821\n",
            "Epoch 435/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4824\n",
            "Epoch 436/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4820\n",
            "Epoch 437/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3277 - val_loss: 0.4830\n",
            "Epoch 438/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4824\n",
            "Epoch 439/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4823\n",
            "Epoch 440/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4827\n",
            "Epoch 441/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3291 - val_loss: 0.4823\n",
            "Epoch 442/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4821\n",
            "Epoch 443/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4821\n",
            "Epoch 444/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3278 - val_loss: 0.4820\n",
            "Epoch 445/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3278 - val_loss: 0.4819\n",
            "Epoch 446/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4834\n",
            "Epoch 447/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4819\n",
            "Epoch 448/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3282 - val_loss: 0.4820\n",
            "Epoch 449/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3278 - val_loss: 0.4820\n",
            "Epoch 450/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4819\n",
            "Epoch 451/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4829\n",
            "Epoch 452/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4823\n",
            "Epoch 453/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4821\n",
            "Epoch 454/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4822\n",
            "Epoch 455/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3282 - val_loss: 0.4818\n",
            "Epoch 456/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3281 - val_loss: 0.4818\n",
            "Epoch 457/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3279 - val_loss: 0.4831\n",
            "Epoch 458/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4821\n",
            "Epoch 459/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3279 - val_loss: 0.4830\n",
            "Epoch 460/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4825\n",
            "Epoch 461/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4821\n",
            "Epoch 462/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3277 - val_loss: 0.4820\n",
            "Epoch 463/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3277 - val_loss: 0.4823\n",
            "Epoch 464/500\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3281 - val_loss: 0.4831\n",
            "Epoch 465/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.4826\n",
            "Epoch 466/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4820\n",
            "Epoch 467/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4818\n",
            "Epoch 468/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4833\n",
            "Epoch 469/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4822\n",
            "Epoch 470/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4820\n",
            "Epoch 471/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4819\n",
            "Epoch 472/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.4827\n",
            "Epoch 473/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3278 - val_loss: 0.4819\n",
            "Epoch 474/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4820\n",
            "Epoch 475/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3278 - val_loss: 0.4820\n",
            "Epoch 476/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3278 - val_loss: 0.4821\n",
            "Epoch 477/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4821\n",
            "Epoch 478/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4821\n",
            "Epoch 479/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4829\n",
            "Epoch 480/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4822\n",
            "Epoch 481/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4819\n",
            "Epoch 482/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4820\n",
            "Epoch 483/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.4825\n",
            "Epoch 484/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4826\n",
            "Epoch 485/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3279 - val_loss: 0.4820\n",
            "Epoch 486/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4819\n",
            "Epoch 487/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4819\n",
            "Epoch 488/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4829\n",
            "Epoch 489/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3286 - val_loss: 0.4847\n",
            "Epoch 490/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.4820\n",
            "Epoch 491/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4820\n",
            "Epoch 492/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4822\n",
            "Epoch 493/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.4824\n",
            "Epoch 494/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4820\n",
            "Epoch 495/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3278 - val_loss: 0.4822\n",
            "Epoch 496/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3278 - val_loss: 0.4829\n",
            "Epoch 497/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3278 - val_loss: 0.4818\n",
            "Epoch 498/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3279 - val_loss: 0.4822\n",
            "Epoch 499/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.4823\n",
            "Epoch 500/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.4819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2QWtbwatMgl",
        "outputId": "b2a2d456-031a-401f-c92e-cdc635a8dd28"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.410187304019928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "JCzA1is8qI2B",
        "outputId": "c0cfbe3e-7028-4f36-85b0-89926997038a"
      },
      "source": [
        "#Learning Curve\n",
        "from matplotlib import pyplot\n",
        "pyplot.title('Learning Curves')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('loss')\n",
        "pyplot.plot(tes_ngasal.history['loss'], label='train')\n",
        "pyplot.plot(tes_ngasal.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}